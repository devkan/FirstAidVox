import React, { useEffect, useRef, useState } from 'react';
import { MessageBubble } from './MessageBubble';
import { MedicalCard } from './MedicalCard';
import { ChatInput } from './ChatInput';
import { TypingIndicator } from './TypingIndicator';
import { EmergencyButton } from './EmergencyButton';
import { ConversationProgress } from './ConversationProgress';
import { useMedicalState } from '../../hooks/useAppState';
import { useVoiceAgent } from '../../hooks/useVoiceAgent';
import { conversationalService } from '../../services/conversationalService';
import type { ChatMessage, ChatContainerProps } from './types';

export const ChatContainer = React.memo(function ChatContainer({ className = '' }: ChatContainerProps) {
  const medicalState = useMedicalState();
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [isTyping, setIsTyping] = useState(false);
  const [pendingImage, setPendingImage] = useState<Blob | null>(null);
  const [conversationStarted, setConversationStarted] = useState(false);

  const voiceAgent = useVoiceAgent({
    autoConnect: false,
    pendingImage,
    onImageSent: () => setPendingImage(null)
  });

  // Initialize conversation on first load
  useEffect(() => {
    if (!conversationStarted) {
      conversationalService.startNewConversation();
      setConversationStarted(true);
      
      // Add welcome message
      const welcomeMessage: ChatMessage = {
        id: 'welcome-msg',
        content: "Hello! I'm your medical triage assistant. I'll help assess your symptoms through a series of questions. What's your main concern today?",
        type: 'text',
        timestamp: new Date(),
        isUser: false,
        metadata: {
          isWelcome: true,
          assessment_stage: 'initial'
        }
      };
      setMessages([welcomeMessage]);
    }
  }, [conversationStarted]);

  // Convert conversation history to chat messages
  // NOTE: This effect handles syncing conversationalService messages to chat UI
  // It triggers on medical assessment changes AND periodically to catch voice messages
  useEffect(() => {
    const syncMessages = () => {
      const conversation = conversationalService.getCurrentConversation();
      if (!conversation) return;

      // Skip if we already have messages with hospital data (they're managed by handleSendMessage)
      // Only run on initial load (messages.length === 0 or just welcome message)
      const hasOnlyWelcome = messages.length === 1 && messages[0]?.id === 'welcome-msg';
      const hasHospitalData = messages.some(msg => (msg.metadata?.hospitalData?.length ?? 0) > 0);
      
      // Check if conversation has new messages we haven't displayed yet
      const conversationMsgCount = conversation.messages.length;
      const displayedMsgCount = messages.filter(m => m.id !== 'welcome-msg' && m.type !== 'medical').length;
      const hasNewMessages = conversationMsgCount > displayedMsgCount;
      
      // Don't overwrite messages that have hospital data unless there are new messages
      if (hasHospitalData && !hasNewMessages) {
        console.log('ğŸ“‹ Skipping message sync - hospital data exists and no new messages');
        return;
      }
      
      const shouldSync = messages.length === 0 || hasOnlyWelcome || hasNewMessages;
      
      if (!shouldSync && !medicalState.currentAssessment) {
        return;
      }

      console.log('ğŸ“‹ Syncing messages from conversationalService:', {
        conversationMsgCount,
        displayedMsgCount,
        hasNewMessages,
        hasHospitalData
      });

      const chatMessages: ChatMessage[] = conversation.messages.map((msg) => ({
        id: msg.id,
        content: msg.content,
        type: 'text',
        timestamp: msg.timestamp,
        isUser: msg.role === 'user',
        metadata: {
          ...msg.metadata,
          assessment_stage: msg.metadata?.assessment_stage,
          conversation_stage: conversation.currentStage,
          // Preserve hospital data from message metadata
          hospitalData: msg.metadata?.hospitalData
        }
      }));

      // Add welcome message if no messages yet
      if (chatMessages.length === 0) {
        const welcomeMessage: ChatMessage = {
          id: 'welcome-msg',
          content: "Hello! I'm your medical triage assistant. I'll help assess your symptoms through a series of questions. What's your main concern today?",
          type: 'text',
          timestamp: new Date(),
          isUser: false,
          metadata: {
            isWelcome: true,
            assessment_stage: 'initial'
          }
        };
        chatMessages.unshift(welcomeMessage);
      }

      // Add medical assessment as special message if available and conversation is in final stage
      if (medicalState.currentAssessment && conversation.currentStage === 'final') {
        // Check if medical assessment message already exists
        const hasMedicalMessage = chatMessages.some(msg => msg.type === 'medical');
        if (!hasMedicalMessage) {
          const medicalMessage: ChatMessage = {
            id: `medical-assessment-${Date.now()}`,
            content: medicalState.currentAssessment.advice,
            type: 'medical',
            timestamp: new Date(),
            isUser: false,
            metadata: {
              medicalData: medicalState.currentAssessment,
              urgency: medicalState.currentAssessment.urgencyLevel,
              confidence: medicalState.currentAssessment.confidence,
              assessment_stage: 'final'
            }
          };
          chatMessages.push(medicalMessage);
        }
      }

      setMessages(chatMessages);
    };

    // Initial sync
    syncMessages();

    // Set up interval to check for new voice messages
    const syncInterval = setInterval(syncMessages, 500); // Check every 500ms

    return () => clearInterval(syncInterval);
  }, [medicalState.currentAssessment]); // Trigger on medical assessment changes

  // Auto-scroll to bottom when new messages arrive
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ 
      behavior: 'smooth',
      block: 'end'
    });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Handle message sending with conversational approach
  const handleSendMessage = async (message: string, attachments?: File[]) => {
    if (!message.trim() && !attachments?.length) return;

    try {
      setIsTyping(true);
      
      // Get the image file if provided
      const imageFile = attachments?.length ? attachments[0] : null;
      
      // Get user location if available
      let userLocation;
      try {
        const position = await new Promise<GeolocationPosition>((resolve, reject) => {
          navigator.geolocation.getCurrentPosition(resolve, reject, {
            timeout: 5000,
            enableHighAccuracy: false
          });
        });
        userLocation = {
          latitude: position.coords.latitude,
          longitude: position.coords.longitude
        };
      } catch (error) {
        console.log('Location not available:', error);
      }

      // Send message through conversational service
      const response = await conversationalService.sendMessage(
        message.trim(),
        userLocation,
        imageFile || undefined
      );

      console.log('ğŸ“‹ Conversational response received:', {
        stage: response.assessment_stage,
        urgency: response.urgency_level,
        confidence: response.confidence,
        hasHospitals: !!response.hospital_data?.length,
        hospitalCount: response.hospital_data?.length || 0
      });

      // Debug: Log hospital details
      if (response.hospital_data?.length) {
        console.log('ğŸ¥ Hospital data received from backend:');
        response.hospital_data.forEach((h: any, i: number) => {
          console.log(`  ${i + 1}. ${h.name} (${h.place_type}) - ${h.address} - Lat: ${h.latitude}, Lng: ${h.longitude}`);
        });
      } else {
        console.log('âš ï¸ No hospital data in response. Stage:', response.assessment_stage);
      }

      // Update medical state if this is a final assessment
      if (response.assessment_stage === 'final' || response.urgency_level !== 'moderate') {
        medicalState.setAssessment({
          condition: response.condition,
          urgencyLevel: response.urgency_level as any,
          advice: response.detailed_text,
          confidence: response.confidence,
          hospitalData: response.hospital_data,
          requiresEmergencyServices: response.urgency_level === 'emergency'
        });
      }

      // Store hospital data for this response to persist it
      const currentHospitalData = response.hospital_data;
      console.log('ğŸ’¾ Storing hospital data for message update:', {
        hasData: !!currentHospitalData,
        count: currentHospitalData?.length || 0
      });

      // FIRST: Update messages immediately (before TTS) so text appears first
      const updatedConversation = conversationalService.getCurrentConversation();
      if (updatedConversation) {
        const chatMessages: ChatMessage[] = updatedConversation.messages.map((msg, index) => {
          // Check if this is the latest assistant message
          const isLatestAssistantMessage = msg.role === 'assistant' && 
            index === updatedConversation.messages.length - 1;
          
          // Debug log for hospital data assignment
          if (isLatestAssistantMessage) {
            console.log('ğŸ”„ Assigning hospital data to latest AI message:', {
              msgId: msg.id,
              hasCurrentHospitalData: !!currentHospitalData,
              hasMetadataHospitalData: !!msg.metadata?.hospitalData,
              willUseCurrentData: !!(isLatestAssistantMessage && currentHospitalData)
            });
          }
          
          return {
            id: msg.id,
            content: msg.content,
            type: 'text',
            timestamp: msg.timestamp,
            isUser: msg.role === 'user',
            metadata: {
              ...msg.metadata,
              assessment_stage: msg.metadata?.assessment_stage,
              conversation_stage: updatedConversation.currentStage,
              // Add hospital data to the latest AI message if available
              hospitalData: isLatestAssistantMessage && currentHospitalData ? currentHospitalData : msg.metadata?.hospitalData
            }
          };
        });
        
        // Debug: Check if any message has hospital data
        const messagesWithHospitals = chatMessages.filter(m => (m.metadata?.hospitalData?.length ?? 0) > 0);
        console.log('ğŸ“Š Messages with hospital data after update:', messagesWithHospitals.length);
        
        setMessages(chatMessages);
      }

      // THEN: Play TTS asynchronously (don't await - let it play in background)
      // Convert text to natural human-like speech (not reading everything)
      const textToSpeak = response.brief_text || response.response || '';
      
      // Only play TTS if there's text to speak
      if (textToSpeak.trim()) {
        // Convert to natural speech - summarize key points
        const naturalSpeech = convertToNaturalSpeech(textToSpeak);
        console.log('ğŸ”Š Playing natural TTS:', naturalSpeech.substring(0, 100) + '...');
        
        // Play TTS without blocking - fire and forget
        playBrowserTTS(naturalSpeech).catch(err => {
          console.log('Voice TTS error (non-blocking):', err);
        });
      }
      
    } catch (error) {
      console.error('Failed to send conversational message:', error);
      
      // Add error message to conversation
      conversationalService.addMessage('assistant', 
        'I apologize, but I encountered an error. Please try again or seek immediate medical attention if this is an emergency.'
      );
    } finally {
      setIsTyping(false);
    }
  };

  // Handle voice input with conversational approach
  const handleVoiceInput = async () => {
    try {
      if (voiceAgent.isActive) {
        await voiceAgent.deactivate();
      } else {
        await voiceAgent.activate();
      }
    } catch (error) {
      console.error('Voice input error:', error);
    }
  };

  // Handle emergency call
  const handleEmergencyCall = () => {
    // Emergency contacts logic would go here
    window.open('tel:911', '_self');
  };

  // Detect language from text for TTS
  const detectLanguageForTTS = (text: string): string => {
    // Korean detection
    if (/[ê°€-í£ã„±-ã…ã…-ã…£]/.test(text)) {
      return 'ko-KR';
    }
    // Japanese detection
    if (/[ã²-ã‚–ãƒ°-ãƒºã‚«-ãƒ¿ä¸€-é¾¯ã‚¡-ãƒ´]/.test(text)) {
      return 'ja-JP';
    }
    // Spanish detection (common Spanish words)
    const spanishWords = ['dolor', 'cabeza', 'fiebre', 'mÃ©dico', 'hospital', 'emergencia', 'sÃ­ntomas'];
    if (spanishWords.some(word => text.toLowerCase().includes(word))) {
      return 'es-ES';
    }
    // Default to English
    return 'en-US';
  };

  // Convert formal text to natural speech (human-like summary)
  const convertToNaturalSpeech = (text: string): string => {
    const lang = detectLanguageForTTS(text);
    
    // Clean markdown formatting first
    let cleanText = text
      .replace(/\*\*/g, '')
      .replace(/\*/g, '')
      .replace(/#{1,6}\s/g, '')
      .replace(/BRIEF:|DETAILED:/g, '')
      .trim();

    // Check if this is a final diagnosis (contains diagnosis keywords)
    const isDiagnosis = /ì§„ë‹¨[:\s]|Diagnosis[:\s]|è¨ºæ–­[:\s]|DiagnÃ³stico[:\s]/i.test(cleanText);
    
    if (isDiagnosis) {
      // Extract key information for natural speech
      if (lang === 'ko-KR') {
        // Korean natural speech conversion for diagnosis
        const diagnosisMatch = cleanText.match(/ì§„ë‹¨[:\s]*([^\n*]+)/i);
        const diagnosis = diagnosisMatch ? diagnosisMatch[1].trim() : '';
        
        if (diagnosis) {
          return `${diagnosis}ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ìì„¸í•œ ì¹˜ë£Œ ë°©ë²•ê³¼ ê·¼ì²˜ ë³‘ì› ì •ë³´ëŠ” í™”ë©´ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.`;
        }
      } else if (lang === 'ja-JP') {
        const diagnosisMatch = cleanText.match(/è¨ºæ–­[:\s]*([^\n*]+)/i);
        const diagnosis = diagnosisMatch ? diagnosisMatch[1].trim() : '';
        
        if (diagnosis) {
          return `${diagnosis}ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è©³ã—ã„æƒ…å ±ã¯ç”»é¢ã§ã”ç¢ºèªãã ã•ã„ã€‚`;
        }
      } else if (lang === 'es-ES') {
        const diagnosisMatch = cleanText.match(/DiagnÃ³stico[:\s]*([^\n*]+)/i);
        const diagnosis = diagnosisMatch ? diagnosisMatch[1].trim() : '';
        
        if (diagnosis) {
          return `Parece ser ${diagnosis}. Consulte la pantalla para mÃ¡s informaciÃ³n.`;
        }
      } else {
        // English: More robust diagnosis extraction
        // Try multiple patterns for English diagnosis
        let diagnosis = '';
        
        // Pattern 1: "Diagnosis: Something"
        const pattern1 = cleanText.match(/Diagnosis[:\s]+([^.\n*]+)/i);
        if (pattern1) {
          diagnosis = pattern1[1].trim();
        }
        
        // Pattern 2: "This looks like X" or "appears to be X"
        if (!diagnosis) {
          const pattern2 = cleanText.match(/(?:looks like|appears to be|seems to be|likely|probably)[:\s]+([^.\n*]+)/i);
          if (pattern2) {
            diagnosis = pattern2[1].trim();
          }
        }
        
        // Pattern 3: "Upper respiratory infection" or similar condition names
        if (!diagnosis) {
          const pattern3 = cleanText.match(/(?:Upper|Lower|Common|Viral|Bacterial)\s+[a-zA-Z\s]+(?:infection|cold|flu|fever|pain)/i);
          if (pattern3) {
            diagnosis = pattern3[0].trim();
          }
        }
        
        if (diagnosis) {
          // Clean up the diagnosis text
          diagnosis = diagnosis.replace(/^\s*[-:]\s*/, '').trim();
          return `This looks like ${diagnosis}. Please check the screen for detailed care instructions and nearby hospitals.`;
        }
        
        // Fallback: Extract first meaningful sentence about the condition
        const firstSentence = cleanText.split(/[.!]\s/)[0];
        if (firstSentence && firstSentence.length < 100) {
          return `${firstSentence}. Check the screen for more details.`;
        }
      }
    }
    
    // For non-diagnosis messages (questions, clarifications)
    // Summarize the key content naturally
    if (lang === 'ko-KR') {
      // Korean: Extract the main question/request
      // Remove filler phrases and keep the core message
      let summary = cleanText
        .replace(/ì•Œê² ìŠµë‹ˆë‹¤[.\s]*/g, '')
        .replace(/ê°ì‚¬í•©ë‹ˆë‹¤[.\s]*/g, '')
        .replace(/ë§ì”€í•´ ì£¼ì…”ì„œ[.\s]*/g, '')
        .replace(/ì¦ìƒì„[.\s]*/g, '')
        .trim();
      
      // If it's a question about symptoms, summarize it
      if (summary.includes('ì–¸ì œ') || summary.includes('ì–´ë–¤') || summary.includes('ìˆìœ¼ì‹ ê°€ìš”') || summary.includes('ì•Œë ¤ì£¼')) {
        // Extract the key question parts
        const hasWhen = summary.includes('ì–¸ì œ');
        const hasOther = summary.includes('ë‹¤ë¥¸ ì¦ìƒ') || summary.includes('ë™ë°˜');
        const hasSeverity = summary.includes('ì •ë„') || summary.includes('ì‹¬í•œ');
        
        let naturalQuestion = '';
        if (hasWhen && hasOther) {
          naturalQuestion = 'ì–¸ì œë¶€í„° ì•„í”„ì…¨ê³ , ë‹¤ë¥¸ ì¦ìƒë„ ìˆìœ¼ì‹ ì§€ ì•Œë ¤ì£¼ì„¸ìš”.';
        } else if (hasWhen) {
          naturalQuestion = 'ì–¸ì œë¶€í„° ì¦ìƒì´ ì‹œì‘ë˜ì—ˆë‚˜ìš”?';
        } else if (hasSeverity) {
          naturalQuestion = 'ì¦ìƒì´ ì–¼ë§ˆë‚˜ ì‹¬í•˜ì‹ ê°€ìš”?';
        } else if (hasOther) {
          naturalQuestion = 'ë‹¤ë¥¸ ì¦ìƒë„ ìˆìœ¼ì‹ ê°€ìš”?';
        } else {
          // Keep first meaningful sentence
          naturalQuestion = summary.split(/[.?!]\s*/)[0] + '?';
        }
        return naturalQuestion;
      }
      
      // Default: return cleaned text (max 150 chars)
      return summary.length > 150 ? summary.substring(0, 150) + '...' : summary;
      
    } else if (lang === 'ja-JP') {
      let summary = cleanText
        .replace(/ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™[ã€‚\s]*/g, '')
        .replace(/ã‚ã‹ã‚Šã¾ã—ãŸ[ã€‚\s]*/g, '')
        .trim();
      
      return summary.length > 150 ? summary.substring(0, 150) + '...' : summary;
      
    } else if (lang === 'es-ES') {
      let summary = cleanText
        .replace(/Entiendo[.\s]*/gi, '')
        .replace(/Gracias[.\s]*/gi, '')
        .trim();
      
      return summary.length > 150 ? summary.substring(0, 150) + '...' : summary;
      
    } else {
      // English: Remove filler and summarize
      let summary = cleanText
        .replace(/I understand[.\s]*/gi, '')
        .replace(/Thank you[.\s]*/gi, '')
        .replace(/I see[.\s]*/gi, '')
        .replace(/Based on your symptoms[,.\s]*/gi, '')
        .trim();
      
      // If asking questions, keep them natural
      if (summary.includes('?')) {
        // Extract questions and combine them naturally
        const questions = summary.match(/[^.!?]*\?/g);
        if (questions && questions.length > 0) {
          // Take first 2 questions max and clean them up
          const cleanQuestions = questions.slice(0, 2).map(q => q.trim()).join(' ');
          return cleanQuestions;
        }
      }
      
      // For statements, extract the key message
      const sentences = summary.split(/[.!]\s+/);
      if (sentences.length > 0) {
        // Take first 1-2 meaningful sentences
        const keyMessage = sentences.slice(0, 2).join('. ').trim();
        return keyMessage.length > 150 ? keyMessage.substring(0, 150) + '...' : keyMessage;
      }
      
      return summary.length > 150 ? summary.substring(0, 150) + '...' : summary;
    }
  };

  // Browser TTS fallback function with proper language detection
  const playBrowserTTS = async (text: string): Promise<void> => {
    return new Promise((resolve) => {
      try {
        // Check if Speech Synthesis is supported
        if (!('speechSynthesis' in window)) {
          console.warn('Speech Synthesis not supported in this browser');
          resolve();
          return;
        }

        // Cancel any ongoing speech first
        window.speechSynthesis.cancel();

        // Clean text for TTS - remove markdown formatting
        const cleanText = text
          .replace(/\*\*/g, '') // Remove bold markers
          .replace(/\*/g, '')   // Remove italic markers
          .replace(/#{1,6}\s/g, '') // Remove headers
          .replace(/BRIEF:|DETAILED:/g, '') // Remove section markers
          .trim();

        if (!cleanText) {
          resolve();
          return;
        }

        // Detect language from text content
        const detectedLang = detectLanguageForTTS(cleanText);
        console.log('ğŸ”Š Detected language for TTS:', detectedLang);

        // Create speech utterance
        const utterance = new SpeechSynthesisUtterance(cleanText);
        
        // Configure voice settings based on language
        utterance.lang = detectedLang;
        utterance.rate = detectedLang === 'ko-KR' ? 0.9 : 0.85; // Korean slightly faster
        utterance.pitch = 1.0;
        utterance.volume = 0.9;

        // Try to find a voice for the detected language
        const voices = window.speechSynthesis.getVoices();
        const matchingVoice = voices.find(voice => voice.lang.startsWith(detectedLang.split('-')[0]));
        if (matchingVoice) {
          utterance.voice = matchingVoice;
          console.log('ğŸ”Š Using voice:', matchingVoice.name);
        }

        // Set up event handlers
        utterance.onend = () => {
          console.log('ğŸ”Š Browser TTS playback completed');
          resolve();
        };
        
        utterance.onerror = (event) => {
          console.error('ğŸ”Š Browser TTS error:', event.error);
          resolve();
        };

        utterance.onstart = () => {
          console.log('ğŸ”Š Browser TTS playback started for language:', detectedLang);
        };

        // Start speaking
        window.speechSynthesis.speak(utterance);
        
        // Safety timeout - much longer to allow full speech (5 minutes max)
        // Don't cancel speech, just resolve the promise
        const safetyTimeout = setTimeout(() => {
          console.log('ğŸ”Š TTS safety timeout reached, but not canceling speech');
          resolve();
        }, 300000); // 5 minutes max

        // Clear timeout when speech ends naturally
        utterance.onend = () => {
          clearTimeout(safetyTimeout);
          console.log('ğŸ”Š Browser TTS playback completed naturally');
          resolve();
        };
        
      } catch (error) {
        console.error('ğŸ”Š Browser TTS initialization error:', error);
        resolve();
      }
    });
  };

  return (
    <div className={`flex flex-col h-screen bg-gradient-to-br from-medical-50 to-chat-background ${className}`}>
      {/* Header */}
      <header className="flex-shrink-0 bg-white/80 backdrop-blur-md border-b border-chat-border safe-area-top">
        <div className="px-3 py-2 sm:px-4 sm:py-3 lg:px-6">
          <div className="flex items-center justify-between">
            <div className="flex items-center space-x-2 sm:space-x-3">
              <div className="w-6 h-6 sm:w-8 sm:h-8 bg-gradient-to-br from-medical-500 to-medical-600 rounded-full flex items-center justify-center">
                <svg className="w-3 h-3 sm:w-5 sm:h-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4.318 6.318a4.5 4.5 0 000 6.364L12 20.364l7.682-7.682a4.5 4.5 0 00-6.364-6.364L12 7.636l-1.318-1.318a4.5 4.5 0 00-6.364 0z" />
                </svg>
              </div>
              <div>
                <h1 className="text-base sm:text-lg font-semibold text-gray-900">FirstAidVox</h1>
                <p className="text-xs sm:text-sm text-gray-500 hidden xs:block">AI Medical Assistant</p>
              </div>
            </div>
            
            {/* Status and Language Selection */}
            <div className="flex items-center space-x-2 sm:space-x-3">
              {/* Language Selection */}
              <select
                value={voiceAgent.getLanguagePreference()}
                onChange={(e) => voiceAgent.setLanguagePreference(e.target.value)}
                className="text-xs sm:text-sm bg-white border border-gray-300 rounded-md px-2 py-1 focus:outline-none focus:ring-2 focus:ring-medical-500 focus:border-transparent"
                title="Select voice recognition language"
              >
                <option value="auto">ğŸŒ Auto</option>
                <option value="en-US">ğŸ‡ºğŸ‡¸ English</option>
                <option value="ko-KR">ğŸ‡°ğŸ‡· í•œêµ­ì–´</option>
                <option value="ja-JP">ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª</option>
                <option value="es-ES">ğŸ‡ªğŸ‡¸ EspaÃ±ol</option>
              </select>
              
              {/* Status indicators */}
              {medicalState.isProcessing && (
                <div className="flex items-center space-x-1 sm:space-x-2 text-medical-600">
                  <div className="w-1.5 h-1.5 sm:w-2 sm:h-2 bg-medical-500 rounded-full animate-pulse"></div>
                  <span className="text-xs sm:text-sm font-medium hidden xs:inline">Analyzing...</span>
                </div>
              )}
              
              {voiceAgent.isActive && (
                <div className="flex items-center space-x-1 sm:space-x-2 text-safe-600">
                  <div className="w-1.5 h-1.5 sm:w-2 sm:h-2 bg-safe-500 rounded-full animate-pulse"></div>
                  <span className="text-xs sm:text-sm font-medium hidden xs:inline">
                    {voiceAgent.isListening ? 'Listening...' : 'Voice Ready'}
                  </span>
                </div>
              )}
            </div>
          </div>
        </div>
      </header>

      {/* Messages Area */}
      <main className="flex-1 overflow-hidden">
        <div className="h-full overflow-y-auto chat-scrollbar px-3 py-3 sm:px-4 sm:py-4 lg:px-6">
          <div className="max-w-2xl sm:max-w-3xl lg:max-w-4xl mx-auto space-y-3 sm:space-y-4">
            
            {/* Conversation Progress Tracker */}
            <ConversationProgress className="sticky top-0 z-10" />
            
            {messages.length === 0 ? (
              // Welcome message
              <div className="text-center py-8 sm:py-12">
                <div className="w-12 h-12 sm:w-16 sm:h-16 bg-gradient-to-br from-medical-500 to-medical-600 rounded-full mx-auto mb-3 sm:mb-4 flex items-center justify-center">
                  <svg className="w-6 h-6 sm:w-8 sm:h-8 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z" />
                  </svg>
                </div>
                <h2 className="text-lg sm:text-xl font-semibold text-gray-900 mb-2">Welcome to FirstAidVox</h2>
                <p className="text-sm sm:text-base text-gray-600 max-w-xs sm:max-w-md mx-auto px-4">
                  I'm your AI medical assistant. Describe your symptoms or ask any health-related questions to get started. I can respond in English, í•œêµ­ì–´, æ—¥æœ¬èª, or EspaÃ±ol.
                </p>
                <div className="mt-4 sm:mt-6 flex flex-wrap justify-center gap-1.5 sm:gap-2 px-4">
                  <button 
                    onClick={() => handleSendMessage("I have a headache")}
                    className="px-3 py-1.5 sm:px-4 sm:py-2 bg-medical-100 text-medical-700 rounded-full text-xs sm:text-sm hover:bg-medical-200 transition-colors"
                  >
                    "I have a headache"
                  </button>
                  <button 
                    onClick={() => handleSendMessage("ë¨¸ë¦¬ê°€ ì•„íŒŒìš”")}
                    className="px-3 py-1.5 sm:px-4 sm:py-2 bg-medical-100 text-medical-700 rounded-full text-xs sm:text-sm hover:bg-medical-200 transition-colors"
                  >
                    "ë¨¸ë¦¬ê°€ ì•„íŒŒìš”"
                  </button>
                  <button 
                    onClick={() => handleSendMessage("I feel dizzy")}
                    className="px-3 py-1.5 sm:px-4 sm:py-2 bg-medical-100 text-medical-700 rounded-full text-xs sm:text-sm hover:bg-medical-200 transition-colors"
                  >
                    "I feel dizzy"
                  </button>
                  <button 
                    onClick={() => handleSendMessage("First aid for cuts")}
                    className="px-3 py-1.5 sm:px-4 sm:py-2 bg-medical-100 text-medical-700 rounded-full text-xs sm:text-sm hover:bg-medical-200 transition-colors"
                  >
                    "First aid for cuts"
                  </button>
                </div>
              </div>
            ) : (
              // Messages list
              messages.map((message) => (
                <div key={message.id} className="message-enter">
                  {message.type === 'medical' && message.metadata?.medicalData ? (
                    <MedicalCard
                      assessment={message.metadata.medicalData}
                      timestamp={message.timestamp}
                      className="mb-3 sm:mb-4"
                    />
                  ) : (
                    <MessageBubble message={message} />
                  )}
                </div>
              ))
            )}

            {/* Typing indicator */}
            <TypingIndicator isVisible={isTyping || medicalState.isProcessing} />

            {/* Scroll anchor */}
            <div ref={messagesEndRef} />
          </div>
        </div>
      </main>

      {/* Chat Input */}
      <ChatInput
        onSendMessage={handleSendMessage}
        onVoiceInput={handleVoiceInput}
        disabled={medicalState.isProcessing}
        placeholder="Describe your symptoms or ask a medical question... (English, í•œêµ­ì–´, æ—¥ë³¸èª, EspaÃ±ol)"
        className="flex-shrink-0 safe-area-bottom"
      />

      {/* Emergency Button */}
      <EmergencyButton
        onEmergencyCall={handleEmergencyCall}
        className="fixed bottom-16 right-3 sm:bottom-20 sm:right-4 lg:bottom-24 lg:right-6 z-50"
      />
    </div>
  );
});